<!DOCTYPE html>
<html >

<head>

  <meta charset="UTF-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <title>R (BGU course)</title>
  <meta name="description" content="Class notes for the R course at the BGU’s IE&amp;M dept.">
  <meta name="generator" content="bookdown 0.3.9 and GitBook 2.6.7">

  <meta property="og:title" content="R (BGU course)" />
  <meta property="og:type" content="book" />
  
  
  <meta property="og:description" content="Class notes for the R course at the BGU’s IE&amp;M dept." />
  

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="R (BGU course)" />
  
  <meta name="twitter:description" content="Class notes for the R course at the BGU’s IE&amp;M dept." />
  

<meta name="author" content="Jonathan D. Rosenblatt">


<meta name="date" content="2017-02-23">

  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta name="apple-mobile-web-app-capable" content="yes">
  <meta name="apple-mobile-web-app-status-bar-style" content="black">
  
  
<link rel="prev" href="eda.html">
<link rel="next" href="glm.html">
<script src="libs/jquery-2.2.3/jquery.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />







<script src="libs/htmlwidgets-0.8/htmlwidgets.js"></script>
<link href="libs/plotlyjs-1.16.3/plotly-htmlwidgets.css" rel="stylesheet" />
<script src="libs/plotlyjs-1.16.3/plotly-latest.min.js"></script>
<script src="libs/plotly-binding-4.5.6/plotly.js"></script>


<style type="text/css">
div.sourceCode { overflow-x: auto; }
table.sourceCode, tr.sourceCode, td.lineNumbers, td.sourceCode {
  margin: 0; padding: 0; vertical-align: baseline; border: none; }
table.sourceCode { width: 100%; line-height: 100%; }
td.lineNumbers { text-align: right; padding-right: 4px; padding-left: 4px; color: #aaaaaa; border-right: 1px solid #aaaaaa; }
td.sourceCode { padding-left: 5px; }
code > span.kw { color: #007020; font-weight: bold; } /* Keyword */
code > span.dt { color: #902000; } /* DataType */
code > span.dv { color: #40a070; } /* DecVal */
code > span.bn { color: #40a070; } /* BaseN */
code > span.fl { color: #40a070; } /* Float */
code > span.ch { color: #4070a0; } /* Char */
code > span.st { color: #4070a0; } /* String */
code > span.co { color: #60a0b0; font-style: italic; } /* Comment */
code > span.ot { color: #007020; } /* Other */
code > span.al { color: #ff0000; font-weight: bold; } /* Alert */
code > span.fu { color: #06287e; } /* Function */
code > span.er { color: #ff0000; font-weight: bold; } /* Error */
code > span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
code > span.cn { color: #880000; } /* Constant */
code > span.sc { color: #4070a0; } /* SpecialChar */
code > span.vs { color: #4070a0; } /* VerbatimString */
code > span.ss { color: #bb6688; } /* SpecialString */
code > span.im { } /* Import */
code > span.va { color: #19177c; } /* Variable */
code > span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code > span.op { color: #666666; } /* Operator */
code > span.bu { } /* BuiltIn */
code > span.ex { } /* Extension */
code > span.pp { color: #bc7a00; } /* Preprocessor */
code > span.at { color: #7d9029; } /* Attribute */
code > span.do { color: #ba2121; font-style: italic; } /* Documentation */
code > span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code > span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code > span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
</style>

<link rel="stylesheet" href="style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">R Course</a></li>

<li class="divider"></li>
<li class="chapter" data-level="1" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i><b>1</b> Preface</a><ul>
<li class="chapter" data-level="1.1" data-path="index.html"><a href="index.html#acknoledgements"><i class="fa fa-check"></i><b>1.1</b> Acknoledgements</a></li>
</ul></li>
<li class="chapter" data-level="2" data-path="intro.html"><a href="intro.html"><i class="fa fa-check"></i><b>2</b> Introduction</a><ul>
<li class="chapter" data-level="2.1" data-path="intro.html"><a href="intro.html#what-r"><i class="fa fa-check"></i><b>2.1</b> What is R?</a></li>
<li class="chapter" data-level="2.2" data-path="intro.html"><a href="intro.html#ecosystem"><i class="fa fa-check"></i><b>2.2</b> The R Ecosystem</a></li>
<li class="chapter" data-level="2.3" data-path="intro.html"><a href="intro.html#bibliographic-notes"><i class="fa fa-check"></i><b>2.3</b> Bibliographic Notes</a></li>
</ul></li>
<li class="chapter" data-level="3" data-path="basics.html"><a href="basics.html"><i class="fa fa-check"></i><b>3</b> R Basics</a><ul>
<li class="chapter" data-level="3.1" data-path="basics.html"><a href="basics.html#simple-calculator"><i class="fa fa-check"></i><b>3.1</b> Simple calculator</a></li>
<li class="chapter" data-level="3.2" data-path="basics.html"><a href="basics.html#probability-calculator"><i class="fa fa-check"></i><b>3.2</b> Probability calculator</a></li>
<li class="chapter" data-level="3.3" data-path="basics.html"><a href="basics.html#getting-help"><i class="fa fa-check"></i><b>3.3</b> Getting Help</a></li>
<li class="chapter" data-level="3.4" data-path="basics.html"><a href="basics.html#variable-asignment"><i class="fa fa-check"></i><b>3.4</b> Variable Asignment</a></li>
<li class="chapter" data-level="3.5" data-path="basics.html"><a href="basics.html#piping"><i class="fa fa-check"></i><b>3.5</b> Piping</a></li>
<li class="chapter" data-level="3.6" data-path="basics.html"><a href="basics.html#vector-creation-and-manipulation"><i class="fa fa-check"></i><b>3.6</b> Vector creation and manipulation</a></li>
<li class="chapter" data-level="3.7" data-path="basics.html"><a href="basics.html#search-paths-and-packages"><i class="fa fa-check"></i><b>3.7</b> Search paths and packages</a></li>
<li class="chapter" data-level="3.8" data-path="basics.html"><a href="basics.html#simple-plotting"><i class="fa fa-check"></i><b>3.8</b> Simple plotting</a></li>
<li class="chapter" data-level="3.9" data-path="basics.html"><a href="basics.html#object-types"><i class="fa fa-check"></i><b>3.9</b> Object types</a></li>
<li class="chapter" data-level="3.10" data-path="basics.html"><a href="basics.html#data-frames"><i class="fa fa-check"></i><b>3.10</b> Data Frames</a></li>
<li class="chapter" data-level="3.11" data-path="basics.html"><a href="basics.html#exctraction"><i class="fa fa-check"></i><b>3.11</b> Exctraction</a></li>
<li class="chapter" data-level="3.12" data-path="basics.html"><a href="basics.html#data-import-and-export"><i class="fa fa-check"></i><b>3.12</b> Data Import and Export</a><ul>
<li class="chapter" data-level="3.12.1" data-path="basics.html"><a href="basics.html#import-from-web"><i class="fa fa-check"></i><b>3.12.1</b> Import from WEB</a></li>
<li class="chapter" data-level="3.12.2" data-path="basics.html"><a href="basics.html#export-as-csv"><i class="fa fa-check"></i><b>3.12.2</b> Export as CSV</a></li>
<li class="chapter" data-level="3.12.3" data-path="basics.html"><a href="basics.html#reading-from-text-files"><i class="fa fa-check"></i><b>3.12.3</b> Reading From Text Files</a></li>
<li class="chapter" data-level="3.12.4" data-path="basics.html"><a href="basics.html#writing-data-to-text-files"><i class="fa fa-check"></i><b>3.12.4</b> Writing Data to Text Files</a></li>
<li class="chapter" data-level="3.12.5" data-path="basics.html"><a href="basics.html#xlsx-files"><i class="fa fa-check"></i><b>3.12.5</b> .XLS(X) files</a></li>
<li class="chapter" data-level="3.12.6" data-path="basics.html"><a href="basics.html#massive-files"><i class="fa fa-check"></i><b>3.12.6</b> Massive files</a></li>
<li class="chapter" data-level="3.12.7" data-path="basics.html"><a href="basics.html#databases"><i class="fa fa-check"></i><b>3.12.7</b> Databases</a></li>
</ul></li>
<li class="chapter" data-level="3.13" data-path="basics.html"><a href="basics.html#functions"><i class="fa fa-check"></i><b>3.13</b> Functions</a></li>
<li class="chapter" data-level="3.14" data-path="basics.html"><a href="basics.html#looping"><i class="fa fa-check"></i><b>3.14</b> Looping</a></li>
<li class="chapter" data-level="3.15" data-path="basics.html"><a href="basics.html#recursion"><i class="fa fa-check"></i><b>3.15</b> Recursion</a></li>
<li class="chapter" data-level="3.16" data-path="basics.html"><a href="basics.html#bibliographic-notes-1"><i class="fa fa-check"></i><b>3.16</b> Bibliographic Notes</a></li>
</ul></li>
<li class="chapter" data-level="4" data-path="eda.html"><a href="eda.html"><i class="fa fa-check"></i><b>4</b> Exploratory Data Analysis</a><ul>
<li class="chapter" data-level="4.1" data-path="eda.html"><a href="eda.html#summary-statistics"><i class="fa fa-check"></i><b>4.1</b> Summary Statistics</a><ul>
<li class="chapter" data-level="4.1.1" data-path="eda.html"><a href="eda.html#categorical-data"><i class="fa fa-check"></i><b>4.1.1</b> Categorical Data</a></li>
<li class="chapter" data-level="4.1.2" data-path="eda.html"><a href="eda.html#continous-data"><i class="fa fa-check"></i><b>4.1.2</b> Continous Data</a></li>
</ul></li>
<li class="chapter" data-level="4.2" data-path="eda.html"><a href="eda.html#visualization"><i class="fa fa-check"></i><b>4.2</b> Visualization</a><ul>
<li class="chapter" data-level="4.2.1" data-path="eda.html"><a href="eda.html#categorical-data-1"><i class="fa fa-check"></i><b>4.2.1</b> Categorical Data</a></li>
<li class="chapter" data-level="4.2.2" data-path="eda.html"><a href="eda.html#continous-data-1"><i class="fa fa-check"></i><b>4.2.2</b> Continous Data</a></li>
</ul></li>
<li class="chapter" data-level="4.3" data-path="eda.html"><a href="eda.html#bibliographic-notes-2"><i class="fa fa-check"></i><b>4.3</b> Bibliographic Notes</a></li>
</ul></li>
<li class="chapter" data-level="5" data-path="lm.html"><a href="lm.html"><i class="fa fa-check"></i><b>5</b> Linear Models</a><ul>
<li class="chapter" data-level="5.1" data-path="lm.html"><a href="lm.html#problem-setup"><i class="fa fa-check"></i><b>5.1</b> Problem Setup</a></li>
<li class="chapter" data-level="5.2" data-path="lm.html"><a href="lm.html#ols-estimation"><i class="fa fa-check"></i><b>5.2</b> OLS Estimation</a></li>
<li class="chapter" data-level="5.3" data-path="lm.html"><a href="lm.html#inference"><i class="fa fa-check"></i><b>5.3</b> Inference</a><ul>
<li class="chapter" data-level="5.3.1" data-path="lm.html"><a href="lm.html#testing-a-hypothesis-on-a-single-coefficient"><i class="fa fa-check"></i><b>5.3.1</b> Testing a Hypothesis on a Single Coefficient</a></li>
<li class="chapter" data-level="5.3.2" data-path="lm.html"><a href="lm.html#constructing-a-confidence-interval-on-a-single-coefficient"><i class="fa fa-check"></i><b>5.3.2</b> Constructing a Confidence Interval on a Single Coefficient</a></li>
<li class="chapter" data-level="5.3.3" data-path="lm.html"><a href="lm.html#multiple-regression"><i class="fa fa-check"></i><b>5.3.3</b> Multiple Regression</a></li>
<li class="chapter" data-level="5.3.4" data-path="lm.html"><a href="lm.html#testing-a-hypothesis-on-a-single-contrast"><i class="fa fa-check"></i><b>5.3.4</b> Testing a Hypothesis on a Single Contrast</a></li>
</ul></li>
<li class="chapter" data-level="5.4" data-path="lm.html"><a href="lm.html#bibliographic-notes-3"><i class="fa fa-check"></i><b>5.4</b> Bibliographic Notes</a></li>
</ul></li>
<li class="chapter" data-level="6" data-path="glm.html"><a href="glm.html"><i class="fa fa-check"></i><b>6</b> Generalized Linear Models</a><ul>
<li class="chapter" data-level="6.1" data-path="glm.html"><a href="glm.html#problem-setup-1"><i class="fa fa-check"></i><b>6.1</b> Problem Setup</a></li>
<li class="chapter" data-level="6.2" data-path="glm.html"><a href="glm.html#logistic-regression"><i class="fa fa-check"></i><b>6.2</b> Logistic Regression</a><ul>
<li class="chapter" data-level="6.2.1" data-path="glm.html"><a href="glm.html#logistic-regression-with-r"><i class="fa fa-check"></i><b>6.2.1</b> Logistic Regression with R</a></li>
</ul></li>
<li class="chapter" data-level="6.3" data-path="glm.html"><a href="glm.html#poisson-regression"><i class="fa fa-check"></i><b>6.3</b> Poisson Regression</a></li>
<li class="chapter" data-level="6.4" data-path="glm.html"><a href="glm.html#extensions"><i class="fa fa-check"></i><b>6.4</b> Extensions</a></li>
<li class="chapter" data-level="6.5" data-path="glm.html"><a href="glm.html#bibliographic-notes-4"><i class="fa fa-check"></i><b>6.5</b> Bibliographic Notes</a></li>
</ul></li>
<li class="chapter" data-level="7" data-path="lme.html"><a href="lme.html"><i class="fa fa-check"></i><b>7</b> Linear Mixed Models</a><ul>
<li class="chapter" data-level="7.1" data-path="lme.html"><a href="lme.html#problem-setup-2"><i class="fa fa-check"></i><b>7.1</b> Problem Setup</a></li>
<li class="chapter" data-level="7.2" data-path="lme.html"><a href="lme.html#mixed-models-with-r"><i class="fa fa-check"></i><b>7.2</b> Mixed Models with R</a><ul>
<li class="chapter" data-level="7.2.1" data-path="lme.html"><a href="lme.html#a-single-random-effect"><i class="fa fa-check"></i><b>7.2.1</b> A Single Random Effect</a></li>
<li class="chapter" data-level="7.2.2" data-path="lme.html"><a href="lme.html#several-random-effects"><i class="fa fa-check"></i><b>7.2.2</b> Several Random Effects</a></li>
<li class="chapter" data-level="7.2.3" data-path="lme.html"><a href="lme.html#a-full-mixed-model"><i class="fa fa-check"></i><b>7.2.3</b> A Full Mixed-Model</a></li>
</ul></li>
<li class="chapter" data-level="7.3" data-path="lme.html"><a href="lme.html#bibliographic-notes-5"><i class="fa fa-check"></i><b>7.3</b> Bibliographic Notes</a></li>
</ul></li>
<li class="chapter" data-level="8" data-path="multivariate.html"><a href="multivariate.html"><i class="fa fa-check"></i><b>8</b> Multivariate Data Analysis</a><ul>
<li class="chapter" data-level="8.1" data-path="multivariate.html"><a href="multivariate.html#signal-detection"><i class="fa fa-check"></i><b>8.1</b> Signal Detection</a></li>
<li class="chapter" data-level="8.2" data-path="multivariate.html"><a href="multivariate.html#signal-counting"><i class="fa fa-check"></i><b>8.2</b> Signal Counting</a></li>
<li class="chapter" data-level="8.3" data-path="multivariate.html"><a href="multivariate.html#signal-identification"><i class="fa fa-check"></i><b>8.3</b> Signal Identification</a></li>
<li class="chapter" data-level="8.4" data-path="multivariate.html"><a href="multivariate.html#signal-estimation"><i class="fa fa-check"></i><b>8.4</b> Signal Estimation</a></li>
<li class="chapter" data-level="8.5" data-path="multivariate.html"><a href="multivariate.html#multivariate-regression"><i class="fa fa-check"></i><b>8.5</b> Multivariate Regression</a></li>
<li class="chapter" data-level="8.6" data-path="multivariate.html"><a href="multivariate.html#distribution-fitting"><i class="fa fa-check"></i><b>8.6</b> Distribution Fitting</a></li>
</ul></li>
<li class="chapter" data-level="9" data-path="supervised.html"><a href="supervised.html"><i class="fa fa-check"></i><b>9</b> Supervised Learning</a><ul>
<li class="chapter" data-level="9.1" data-path="supervised.html"><a href="supervised.html#problem-setup-3"><i class="fa fa-check"></i><b>9.1</b> Problem setup</a><ul>
<li class="chapter" data-level="9.1.1" data-path="supervised.html"><a href="supervised.html#common-hypothesis-classes"><i class="fa fa-check"></i><b>9.1.1</b> Common Hypothesis Classes</a></li>
<li class="chapter" data-level="9.1.2" data-path="supervised.html"><a href="supervised.html#common-complexity-penalties"><i class="fa fa-check"></i><b>9.1.2</b> Common Complexity Penalties</a></li>
<li class="chapter" data-level="9.1.3" data-path="supervised.html"><a href="supervised.html#unbiased-risk-estimation"><i class="fa fa-check"></i><b>9.1.3</b> Unbiased Risk Estimation</a></li>
<li class="chapter" data-level="9.1.4" data-path="supervised.html"><a href="supervised.html#collecting-the-pieces"><i class="fa fa-check"></i><b>9.1.4</b> Collecting the Pieces</a></li>
</ul></li>
<li class="chapter" data-level="9.2" data-path="supervised.html"><a href="supervised.html#supervised-learning-in-r"><i class="fa fa-check"></i><b>9.2</b> Supervised Learning in R</a><ul>
<li class="chapter" data-level="9.2.1" data-path="supervised.html"><a href="supervised.html#least-squares"><i class="fa fa-check"></i><b>9.2.1</b> Linear Models with Least Squares Loss</a></li>
<li class="chapter" data-level="9.2.2" data-path="supervised.html"><a href="supervised.html#svm"><i class="fa fa-check"></i><b>9.2.2</b> SVM</a></li>
<li class="chapter" data-level="9.2.3" data-path="supervised.html"><a href="supervised.html#neural-nets"><i class="fa fa-check"></i><b>9.2.3</b> Neural Nets</a></li>
<li class="chapter" data-level="9.2.4" data-path="supervised.html"><a href="supervised.html#classification-and-regression-trees-cart"><i class="fa fa-check"></i><b>9.2.4</b> Classification and Regression Trees (CART)</a></li>
<li class="chapter" data-level="9.2.5" data-path="supervised.html"><a href="supervised.html#k-nearest-neighbour-knn"><i class="fa fa-check"></i><b>9.2.5</b> K-nearest neighbour (KNN)</a></li>
<li class="chapter" data-level="9.2.6" data-path="supervised.html"><a href="supervised.html#linear-discriminant-analysis-lda"><i class="fa fa-check"></i><b>9.2.6</b> Linear Discriminant Analysis (LDA)</a></li>
<li class="chapter" data-level="9.2.7" data-path="supervised.html"><a href="supervised.html#naive-bayes"><i class="fa fa-check"></i><b>9.2.7</b> Naive Bayes</a></li>
</ul></li>
<li class="chapter" data-level="9.3" data-path="supervised.html"><a href="supervised.html#bibliographic-notes-6"><i class="fa fa-check"></i><b>9.3</b> Bibliographic Notes</a></li>
</ul></li>
<li class="chapter" data-level="10" data-path="unsupervised.html"><a href="unsupervised.html"><i class="fa fa-check"></i><b>10</b> Unsupervised Learning</a><ul>
<li class="chapter" data-level="10.1" data-path="unsupervised.html"><a href="unsupervised.html#dim-reduce"><i class="fa fa-check"></i><b>10.1</b> Dimensionality Reduction</a><ul>
<li class="chapter" data-level="10.1.1" data-path="unsupervised.html"><a href="unsupervised.html#pca"><i class="fa fa-check"></i><b>10.1.1</b> Principal Component Analysis</a></li>
<li class="chapter" data-level="10.1.2" data-path="unsupervised.html"><a href="unsupervised.html#preliminaries"><i class="fa fa-check"></i><b>10.1.2</b> Preliminaries</a></li>
<li class="chapter" data-level="10.1.3" data-path="unsupervised.html"><a href="unsupervised.html#latent-variable-approaches"><i class="fa fa-check"></i><b>10.1.3</b> Latent Variable Approaches</a></li>
<li class="chapter" data-level="10.1.4" data-path="unsupervised.html"><a href="unsupervised.html#purely-algorithmic-approaches"><i class="fa fa-check"></i><b>10.1.4</b> Purely Algorithmic Approaches</a></li>
<li class="chapter" data-level="10.1.5" data-path="unsupervised.html"><a href="unsupervised.html#dimensionality-reduction-in-r"><i class="fa fa-check"></i><b>10.1.5</b> Dimensionality Reduction in R</a></li>
</ul></li>
<li class="chapter" data-level="10.2" data-path="unsupervised.html"><a href="unsupervised.html#cluster"><i class="fa fa-check"></i><b>10.2</b> Clustering</a><ul>
<li class="chapter" data-level="10.2.1" data-path="unsupervised.html"><a href="unsupervised.html#latent-variable-approaches-1"><i class="fa fa-check"></i><b>10.2.1</b> Latent Variable Approaches</a></li>
<li class="chapter" data-level="10.2.2" data-path="unsupervised.html"><a href="unsupervised.html#purely-algorithmic-approaches-1"><i class="fa fa-check"></i><b>10.2.2</b> Purely Algorithmic Approaches</a></li>
<li class="chapter" data-level="10.2.3" data-path="unsupervised.html"><a href="unsupervised.html#clustering-in-r"><i class="fa fa-check"></i><b>10.2.3</b> Clustering in R</a></li>
</ul></li>
<li class="chapter" data-level="10.3" data-path="unsupervised.html"><a href="unsupervised.html#bibliographic-notes-7"><i class="fa fa-check"></i><b>10.3</b> Bibliographic Notes</a></li>
</ul></li>
<li class="chapter" data-level="11" data-path="plotting.html"><a href="plotting.html"><i class="fa fa-check"></i><b>11</b> Plotting</a><ul>
<li class="chapter" data-level="11.1" data-path="plotting.html"><a href="plotting.html#the-graphics-system"><i class="fa fa-check"></i><b>11.1</b> The graphics System</a><ul>
<li class="chapter" data-level="11.1.1" data-path="plotting.html"><a href="plotting.html#using-existing-plotting-functions"><i class="fa fa-check"></i><b>11.1.1</b> Using Existing Plotting Functions</a></li>
<li class="chapter" data-level="11.1.2" data-path="plotting.html"><a href="plotting.html#the-power-of-the-graphics-device"><i class="fa fa-check"></i><b>11.1.2</b> The Power of the graphics device</a></li>
<li class="chapter" data-level="11.1.3" data-path="plotting.html"><a href="plotting.html#exporting-a-plot"><i class="fa fa-check"></i><b>11.1.3</b> Exporting a Plot</a></li>
</ul></li>
<li class="chapter" data-level="11.2" data-path="plotting.html"><a href="plotting.html#the-ggplot2-system"><i class="fa fa-check"></i><b>11.2</b> The ggplot2 System</a></li>
<li class="chapter" data-level="11.3" data-path="plotting.html"><a href="plotting.html#interactive-graphics"><i class="fa fa-check"></i><b>11.3</b> Interactive Graphics</a><ul>
<li class="chapter" data-level="11.3.1" data-path="plotting.html"><a href="plotting.html#plotly"><i class="fa fa-check"></i><b>11.3.1</b> Plotly</a></li>
<li class="chapter" data-level="11.3.2" data-path="plotting.html"><a href="plotting.html#html-widgets"><i class="fa fa-check"></i><b>11.3.2</b> HTML Widgets</a></li>
</ul></li>
<li class="chapter" data-level="11.4" data-path="plotting.html"><a href="plotting.html#bibliographic-notes-8"><i class="fa fa-check"></i><b>11.4</b> Bibliographic Notes</a></li>
</ul></li>
<li class="chapter" data-level="12" data-path="report.html"><a href="report.html"><i class="fa fa-check"></i><b>12</b> Reports</a><ul>
<li class="chapter" data-level="12.1" data-path="report.html"><a href="report.html#knitr"><i class="fa fa-check"></i><b>12.1</b> knitr</a><ul>
<li class="chapter" data-level="12.1.1" data-path="report.html"><a href="report.html#installation"><i class="fa fa-check"></i><b>12.1.1</b> Installation</a></li>
<li class="chapter" data-level="12.1.2" data-path="report.html"><a href="report.html#pandoc-markdown"><i class="fa fa-check"></i><b>12.1.2</b> Pandoc Markdown</a></li>
<li class="chapter" data-level="12.1.3" data-path="report.html"><a href="report.html#rmarkdown"><i class="fa fa-check"></i><b>12.1.3</b> Rmarkdown</a></li>
<li class="chapter" data-level="12.1.4" data-path="report.html"><a href="report.html#compiling"><i class="fa fa-check"></i><b>12.1.4</b> Compiling</a></li>
</ul></li>
<li class="chapter" data-level="12.2" data-path="report.html"><a href="report.html#bookdown"><i class="fa fa-check"></i><b>12.2</b> bookdown</a></li>
<li class="chapter" data-level="12.3" data-path="report.html"><a href="report.html#shiny"><i class="fa fa-check"></i><b>12.3</b> Shiny</a><ul>
<li class="chapter" data-level="12.3.1" data-path="report.html"><a href="report.html#installation-1"><i class="fa fa-check"></i><b>12.3.1</b> Installation</a></li>
<li class="chapter" data-level="12.3.2" data-path="report.html"><a href="report.html#the-basics-of-shiny"><i class="fa fa-check"></i><b>12.3.2</b> The Basics of Shiny</a></li>
<li class="chapter" data-level="12.3.3" data-path="report.html"><a href="report.html#beyond-the-basics"><i class="fa fa-check"></i><b>12.3.3</b> Beyond the Basics</a></li>
</ul></li>
<li class="chapter" data-level="12.4" data-path="report.html"><a href="report.html#bibliographic-notes-9"><i class="fa fa-check"></i><b>12.4</b> Bibliographic Notes</a></li>
</ul></li>
<li class="chapter" data-level="13" data-path="hadley.html"><a href="hadley.html"><i class="fa fa-check"></i><b>13</b> The Hadleyverse</a><ul>
<li class="chapter" data-level="13.1" data-path="hadley.html"><a href="hadley.html#readr"><i class="fa fa-check"></i><b>13.1</b> readr</a></li>
<li class="chapter" data-level="13.2" data-path="hadley.html"><a href="hadley.html#dplyr"><i class="fa fa-check"></i><b>13.2</b> dplyr</a></li>
<li class="chapter" data-level="13.3" data-path="hadley.html"><a href="hadley.html#tidyr"><i class="fa fa-check"></i><b>13.3</b> tidyr</a></li>
<li class="chapter" data-level="13.4" data-path="hadley.html"><a href="hadley.html#reshape2"><i class="fa fa-check"></i><b>13.4</b> reshape2</a></li>
<li class="chapter" data-level="13.5" data-path="hadley.html"><a href="hadley.html#stringr"><i class="fa fa-check"></i><b>13.5</b> stringr</a></li>
<li class="chapter" data-level="13.6" data-path="hadley.html"><a href="hadley.html#anytime"><i class="fa fa-check"></i><b>13.6</b> anytime</a></li>
<li class="chapter" data-level="13.7" data-path="hadley.html"><a href="hadley.html#biblipgraphic-notes"><i class="fa fa-check"></i><b>13.7</b> Biblipgraphic Notes</a></li>
</ul></li>
<li class="chapter" data-level="14" data-path="sparse.html"><a href="sparse.html"><i class="fa fa-check"></i><b>14</b> Sparse Representations</a><ul>
<li class="chapter" data-level="14.1" data-path="sparse.html"><a href="sparse.html#sparse-matrix-representations"><i class="fa fa-check"></i><b>14.1</b> Sparse Matrix Representations</a><ul>
<li class="chapter" data-level="14.1.1" data-path="sparse.html"><a href="sparse.html#coo"><i class="fa fa-check"></i><b>14.1.1</b> Coordinate List Representation</a></li>
<li class="chapter" data-level="14.1.2" data-path="sparse.html"><a href="sparse.html#compressed-column-oriented-representation"><i class="fa fa-check"></i><b>14.1.2</b> Compressed Column Oriented Representation</a></li>
<li class="chapter" data-level="14.1.3" data-path="sparse.html"><a href="sparse.html#compressed-row-oriented-representation"><i class="fa fa-check"></i><b>14.1.3</b> Compressed Row Oriented Representation</a></li>
<li class="chapter" data-level="14.1.4" data-path="sparse.html"><a href="sparse.html#sparse-algorithms"><i class="fa fa-check"></i><b>14.1.4</b> Sparse Algorithms</a></li>
</ul></li>
<li class="chapter" data-level="14.2" data-path="sparse.html"><a href="sparse.html#sparse-matrices-and-sparse-models-in-r"><i class="fa fa-check"></i><b>14.2</b> Sparse Matrices and Sparse Models in R</a><ul>
<li class="chapter" data-level="14.2.1" data-path="sparse.html"><a href="sparse.html#the-matrix-package"><i class="fa fa-check"></i><b>14.2.1</b> The Matrix Package</a></li>
<li class="chapter" data-level="14.2.2" data-path="sparse.html"><a href="sparse.html#the-glmnet-package"><i class="fa fa-check"></i><b>14.2.2</b> The glmnet Package</a></li>
</ul></li>
<li class="chapter" data-level="14.3" data-path="sparse.html"><a href="sparse.html#bibliographic-notes-10"><i class="fa fa-check"></i><b>14.3</b> Bibliographic Notes</a></li>
</ul></li>
<li class="chapter" data-level="15" data-path="memory.html"><a href="memory.html"><i class="fa fa-check"></i><b>15</b> Memory Efficiency</a><ul>
<li class="chapter" data-level="15.1" data-path="memory.html"><a href="memory.html#efficient-computing-from-ram"><i class="fa fa-check"></i><b>15.1</b> Efficient Computing from RAM</a><ul>
<li class="chapter" data-level="15.1.1" data-path="memory.html"><a href="memory.html#summary-statistics-from-ram"><i class="fa fa-check"></i><b>15.1.1</b> Summary Statistics from RAM</a></li>
</ul></li>
<li class="chapter" data-level="15.2" data-path="memory.html"><a href="memory.html#computing-from-a-database"><i class="fa fa-check"></i><b>15.2</b> Computing from a Database</a></li>
<li class="chapter" data-level="15.3" data-path="memory.html"><a href="memory.html#file-structure"><i class="fa fa-check"></i><b>15.3</b> Computing From Efficient File Structrures</a></li>
<li class="chapter" data-level="15.4" data-path="memory.html"><a href="memory.html#computing-from-a-distributed-file-system"><i class="fa fa-check"></i><b>15.4</b> Computing from a distributed file system</a></li>
<li class="chapter" data-level="15.5" data-path="memory.html"><a href="memory.html#bibliographic-notes-11"><i class="fa fa-check"></i><b>15.5</b> Bibliographic Notes</a></li>
</ul></li>
<li class="chapter" data-level="16" data-path="parallel.html"><a href="parallel.html"><i class="fa fa-check"></i><b>16</b> Parallel Computing</a><ul>
<li class="chapter" data-level="16.1" data-path="parallel.html"><a href="parallel.html#bibliographic-notes-12"><i class="fa fa-check"></i><b>16.1</b> Bibliographic Notes</a></li>
</ul></li>
<li class="chapter" data-level="17" data-path="algebra.html"><a href="algebra.html"><i class="fa fa-check"></i><b>17</b> Numerical Linear Algebra</a></li>
<li class="chapter" data-level="18" data-path="convex.html"><a href="convex.html"><i class="fa fa-check"></i><b>18</b> Convex Optimization</a></li>
<li class="chapter" data-level="19" data-path="rcpp.html"><a href="rcpp.html"><i class="fa fa-check"></i><b>19</b> RCpp</a></li>
<li class="chapter" data-level="20" data-path="package.html"><a href="package.html"><i class="fa fa-check"></i><b>20</b> Writing Packages</a></li>
<li class="chapter" data-level="21" data-path="bib.html"><a href="bib.html"><i class="fa fa-check"></i><b>21</b> Bibliography</a></li>
<li class="divider"></li>
<li><a href="https://github.com/rstudio/bookdown" target="blank">Published with bookdown</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">R (BGU course)</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="lm" class="section level1">
<h1><span class="header-section-number">Chapter 5</span> Linear Models</h1>
<div id="problem-setup" class="section level2">
<h2><span class="header-section-number">5.1</span> Problem Setup</h2>

<div class="example">
<span id="ex:cap-experiment" class="example"><strong>Example 5.1 </strong></span>Consider a randomized experiment designed to study the effects of temperature and pressure on the diameter of a bottle cap.
</div>
<p></p>

<div class="example">
<span id="ex:rental" class="example"><strong>Example 5.2 </strong></span>Consider the prediction of rental prices given an appartment’s attributes.
</div>
<p></p>
<p>Both examples require some statistical model, but they are very different. The first is a <em>causal inference</em> problem: we want to design an intervention so that we need to recover the causal effect of temperature and pressure. The second is a <em>prediction</em> problem. We don’t care about the causal effects, we just want good predictions.</p>
<p>In this chapter we discuss the causal problem in Example <a href="lm.html#ex:cap-experiment">5.1</a>. This means that when we assume a model, we assume it is the actual <em>data generating process</em>. The second type of problems is discussed in the Supervised Learning Chapter <a href="supervised.html#supervised">9</a>.</p>
<p>Lets present the linear model. We assume that a response<a href="#fn5" class="footnoteRef" id="fnref5"><sup>5</sup></a> variable is the sum of effects of some factors<a href="#fn6" class="footnoteRef" id="fnref6"><sup>6</sup></a>. Denoting the dependent by <span class="math inline">\(y\)</span>, the factors by <span class="math inline">\(x\)</span>, and the effects by <span class="math inline">\(\beta\)</span> the linear model assumption implies that</p>
<span class="math display" id="eq:linear-mean">\[\begin{align}
  E[y]=\sum_j x_j \beta_j=x&#39;\beta .
  \tag{5.1}
\end{align}\]</span>
Clearly, there may be other factors that affect the the caps’ diameters. We thus introduce an error term<a href="#fn7" class="footnoteRef" id="fnref7"><sup>7</sup></a>, denoted by <span class="math inline">\(\varepsilon\)</span>, to capture the effects of all unmodeled factors. The implied generative process of a sample of <span class="math inline">\(i=1,\dots,n\)</span> observations it thus
<span class="math display" id="eq:linear-observed">\[\begin{align}
  y_i = \sum x_{i,j} \beta_j + \varepsilon_i , i=1,\dots,n .
  \tag{5.2}
\end{align}\]</span>
or in matrix notation
<span class="math display" id="eq:linear-matrix">\[\begin{align}
  y = X \beta + \varepsilon .
  \tag{5.3}
\end{align}\]</span>
<p>Lets demonstrate Eq.<a href="lm.html#eq:linear-observed">(5.2)</a>:</p>
<p>In our cap example, assuming that pressure and temperature have two levels each (say, high and low), we would write <span class="math inline">\(x_{i,1}=1\)</span> if the pressure of the <span class="math inline">\(i\)</span>’th measurement was set to high, and <span class="math inline">\(x_{i,1}=-1\)</span> if the pressure was set to low. Similarly, we would write <span class="math inline">\(x_{i,2}=1\)</span>, and <span class="math inline">\(x_{i,2}=-1\)</span>, if the temperature was set to high, or low, respectively. The coding with <span class="math inline">\(\{-1,1\}\)</span> is known as <em>effect coding</em>. If you prefer coding with <span class="math inline">\(\{0,1\}\)</span>, this is known as <em>dummy coding</em>.</p>
<p>In Gosset’s classical regression problem, where we try to seek the relation between the heights of sons and fathers then <span class="math inline">\(p=1\)</span>, <span class="math inline">\(y_i\)</span> is the height of the <span class="math inline">\(i\)</span>’th father, and <span class="math inline">\(x_i\)</span> the height of the <span class="math inline">\(i\)</span>’th son.</p>
<p>There are many reasons these models are so popular:</p>
<ol style="list-style-type: decimal">
<li><p>Before the computer age, these were pretty much the only models that could actually be computed<a href="#fn8" class="footnoteRef" id="fnref8"><sup>8</sup></a>. The whole Analysis of Variance (ANOVA) literature is an instance of linear models.</p></li>
<li><p>For purposes of prediction, where the actual data generating process is not of primary importance, they are popular because they simply work. Why is that? They are simple so that they do not require a lot of data to be computed. Put differently, they may be biased, but their variance is small enough to make them more accurate than other models.</p></li>
<li><p>For categorical or factorial predictors, <strong>any</strong> functional relation can be cast as a linear model.</p></li>
<li><p>For the purpose of <em>screening</em>, where we only want to show the existence of an effect, and are less interested in the magnitude of the effect, a linear model is enough.</p></li>
<li><p>If the true generative relation is not linear, but smooth enough, then the linear function is a good approximation via Taylor’s theorem.</p></li>
</ol>
<p>There are still two matters we have to attend: How the estimate <span class="math inline">\(\beta\)</span>, and how to perform inference.</p>
<p>In linear models the estimation of <span class="math inline">\(\beta\)</span> is done using the method of least squares. For this reason, a linear model with least squares estimation is known as Ordinary Least Squares (OLS). The OLS problem:</p>
<span class="math display" id="eq:ols">\[\begin{align}
  \hat \beta_{OLS}:= argmin_\beta \{ \sum_i (y_i-x_i&#39;\beta)^2 \},
  \tag{5.4}
\end{align}\]</span>
and in matrix notation
<span class="math display" id="eq:ols-matrix">\[\begin{align}
  \hat \beta_{OLS}:= argmin_\beta \{ \Vert y-X\beta \Vert^2_2 \}.
  \tag{5.5}
\end{align}\]</span>

<div class="remark">
<span class="remark"><em>Remark. </em></span> Personally, I prefer the matrix notation because it suggests of the geometry of the problem. The reader is referred to <span class="citation">Friedman, Hastie, and Tibshirani (<a href="#ref-friedman2001elements">2001</a>)</span>, Sec 3.2, for more on the geometry of OLS.
</div>
<p></p>
<p>Different software suits, and even different R packages, solve Eq.<a href="lm.html#eq:ols">(5.4)</a> in different ways so that we skip the details of how exactly it is solved.</p>
<p>The last matter we need to attend is how to do inference on <span class="math inline">\(\hat \beta_{OLS}\)</span>. For that, we will need some assumptions on <span class="math inline">\(\varepsilon\)</span>. A typical set of assumptions is the following:</p>
<ol style="list-style-type: decimal">
<li><strong>Independence</strong>: we assume <span class="math inline">\(\varepsilon_i\)</span> are independent of everything else. Think of them as the measurement error of an instrument: it is independent of the measured value and of previous measurements.</li>
<li><strong>Centered</strong>: we assume that <span class="math inline">\(E[\varepsilon]=0\)</span>, meaning there is no systematic error.</li>
<li><strong>Normality</strong>: we will typically assume that <span class="math inline">\(\varepsilon \sim \mathcal{N}(0,\sigma^2)\)</span>, but we will later see that this is not really required.</li>
</ol>
<p>We emphasize that these assumptions are only needed for inference on <span class="math inline">\(\hat \beta\)</span> and not for the estimation itself, which is done by the purely algorithmic framework of OLS.</p>
Given the above assumptions, we can apply some probability theory and linear algebra to get
<span class="math display" id="eq:ols-distribution">\[\begin{align}
  \hat \beta_{OLS} \sim \mathcal{N}(\beta, (X&#39;X)^{-1} \sigma^2)
  \tag{5.6}
\end{align}\]</span>
<p>The reason I am not too strict about the normality assumption above, is that Eq.<a href="lm.html#eq:ols-distribution">(5.6)</a> is approximately correct even if <span class="math inline">\(\varepsilon\)</span> is not normal, provided that there are many more observations than factors (<span class="math inline">\(n \gg p\)</span>).</p>
</div>
<div id="ols-estimation" class="section level2">
<h2><span class="header-section-number">5.2</span> OLS Estimation</h2>
<p>We are now ready to estimate some linear models with R. We will use the <code>whiteside</code> data from the <strong>MASS</strong> package,recording the outside temperature and gas consumption, before and after insulation.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">library</span>(MASS)
<span class="kw">data</span>(whiteside)
<span class="kw">head</span>(whiteside) <span class="co"># inspect the data</span></code></pre></div>
<pre><code>##    Insul Temp Gas
## 1 Before -0.8 7.2
## 2 Before -0.7 6.9
## 3 Before  0.4 6.4
## 4 Before  2.5 6.0
## 5 Before  2.9 5.8
## 6 Before  3.2 5.8</code></pre>
<p>We do the OLS estimation with <code>lm</code> function, possibly the most important function in R.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">lm<span class="fl">.1</span> &lt;-<span class="st"> </span><span class="kw">lm</span>(Gas~Temp, <span class="dt">data=</span>whiteside[whiteside$Insul==<span class="st">&#39;Before&#39;</span>,]) <span class="co"># OLS estimation </span></code></pre></div>
<p>Things to note:</p>
<ul>
<li>We used the tilde syntax <code>Gas~Temp</code>, reading “gas as linear function of temperature”.</li>
<li>The <code>data</code> argument tells R where to look for the variables Gas and Temp. We used only observations before the insulation.</li>
<li>The result is assigned to the object <code>lm.1</code>.</li>
</ul>
<p>Alternative formulations with the same results would be</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">lm<span class="fl">.1</span> &lt;-<span class="st"> </span><span class="kw">lm</span>(<span class="dt">y=</span>Gas, <span class="dt">x=</span>Temp, <span class="dt">data=</span>whiteside[whiteside$Insul==<span class="st">&#39;Before&#39;</span>,]) 
lm<span class="fl">.1</span> &lt;-<span class="st"> </span><span class="kw">lm</span>(<span class="dt">y=</span>whiteside[whiteside$Insul==<span class="st">&#39;Before&#39;</span>,]$Gas, <span class="dt">x=</span>whiteside[whiteside$Insul==<span class="st">&#39;Before&#39;</span>,]$Temp)  </code></pre></div>
<p>The output is an object of class <code>lm</code>.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">class</span>(lm<span class="fl">.1</span>)</code></pre></div>
<pre><code>## [1] &quot;lm&quot;</code></pre>
<p>Objects of class <code>lm</code> are very complicated. It stored a lot of information which will be later used for inference, plotting, etc. The <code>str</code> function, short for “structure” shows us the various elements of the object.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">str</span>(lm<span class="fl">.1</span>)</code></pre></div>
<pre><code>## List of 12
##  $ coefficients : Named num [1:2] 6.854 -0.393
##   ..- attr(*, &quot;names&quot;)= chr [1:2] &quot;(Intercept)&quot; &quot;Temp&quot;
##  $ residuals    : Named num [1:26] 0.0316 -0.2291 -0.2965 0.1293 0.0866 ...
##   ..- attr(*, &quot;names&quot;)= chr [1:26] &quot;1&quot; &quot;2&quot; &quot;3&quot; &quot;4&quot; ...
##  $ effects      : Named num [1:26] -24.2203 -5.6485 -0.2541 0.1463 0.0988 ...
##   ..- attr(*, &quot;names&quot;)= chr [1:26] &quot;(Intercept)&quot; &quot;Temp&quot; &quot;&quot; &quot;&quot; ...
##  $ rank         : int 2
##  $ fitted.values: Named num [1:26] 7.17 7.13 6.7 5.87 5.71 ...
##   ..- attr(*, &quot;names&quot;)= chr [1:26] &quot;1&quot; &quot;2&quot; &quot;3&quot; &quot;4&quot; ...
##  $ assign       : int [1:2] 0 1
##  $ qr           :List of 5
##   ..$ qr   : num [1:26, 1:2] -5.099 0.196 0.196 0.196 0.196 ...
##   .. ..- attr(*, &quot;dimnames&quot;)=List of 2
##   .. .. ..$ : chr [1:26] &quot;1&quot; &quot;2&quot; &quot;3&quot; &quot;4&quot; ...
##   .. .. ..$ : chr [1:2] &quot;(Intercept)&quot; &quot;Temp&quot;
##   .. ..- attr(*, &quot;assign&quot;)= int [1:2] 0 1
##   ..$ qraux: num [1:2] 1.2 1.35
##   ..$ pivot: int [1:2] 1 2
##   ..$ tol  : num 1e-07
##   ..$ rank : int 2
##   ..- attr(*, &quot;class&quot;)= chr &quot;qr&quot;
##  $ df.residual  : int 24
##  $ xlevels      : Named list()
##  $ call         : language lm(formula = Gas ~ Temp, data = whiteside[whiteside$Insul == &quot;Before&quot;,      ])
##  $ terms        :Classes &#39;terms&#39;, &#39;formula&#39;  language Gas ~ Temp
##   .. ..- attr(*, &quot;variables&quot;)= language list(Gas, Temp)
##   .. ..- attr(*, &quot;factors&quot;)= int [1:2, 1] 0 1
##   .. .. ..- attr(*, &quot;dimnames&quot;)=List of 2
##   .. .. .. ..$ : chr [1:2] &quot;Gas&quot; &quot;Temp&quot;
##   .. .. .. ..$ : chr &quot;Temp&quot;
##   .. ..- attr(*, &quot;term.labels&quot;)= chr &quot;Temp&quot;
##   .. ..- attr(*, &quot;order&quot;)= int 1
##   .. ..- attr(*, &quot;intercept&quot;)= int 1
##   .. ..- attr(*, &quot;response&quot;)= int 1
##   .. ..- attr(*, &quot;.Environment&quot;)=&lt;environment: R_GlobalEnv&gt; 
##   .. ..- attr(*, &quot;predvars&quot;)= language list(Gas, Temp)
##   .. ..- attr(*, &quot;dataClasses&quot;)= Named chr [1:2] &quot;numeric&quot; &quot;numeric&quot;
##   .. .. ..- attr(*, &quot;names&quot;)= chr [1:2] &quot;Gas&quot; &quot;Temp&quot;
##  $ model        :&#39;data.frame&#39;:   26 obs. of  2 variables:
##   ..$ Gas : num [1:26] 7.2 6.9 6.4 6 5.8 5.8 5.6 4.7 5.8 5.2 ...
##   ..$ Temp: num [1:26] -0.8 -0.7 0.4 2.5 2.9 3.2 3.6 3.9 4.2 4.3 ...
##   ..- attr(*, &quot;terms&quot;)=Classes &#39;terms&#39;, &#39;formula&#39;  language Gas ~ Temp
##   .. .. ..- attr(*, &quot;variables&quot;)= language list(Gas, Temp)
##   .. .. ..- attr(*, &quot;factors&quot;)= int [1:2, 1] 0 1
##   .. .. .. ..- attr(*, &quot;dimnames&quot;)=List of 2
##   .. .. .. .. ..$ : chr [1:2] &quot;Gas&quot; &quot;Temp&quot;
##   .. .. .. .. ..$ : chr &quot;Temp&quot;
##   .. .. ..- attr(*, &quot;term.labels&quot;)= chr &quot;Temp&quot;
##   .. .. ..- attr(*, &quot;order&quot;)= int 1
##   .. .. ..- attr(*, &quot;intercept&quot;)= int 1
##   .. .. ..- attr(*, &quot;response&quot;)= int 1
##   .. .. ..- attr(*, &quot;.Environment&quot;)=&lt;environment: R_GlobalEnv&gt; 
##   .. .. ..- attr(*, &quot;predvars&quot;)= language list(Gas, Temp)
##   .. .. ..- attr(*, &quot;dataClasses&quot;)= Named chr [1:2] &quot;numeric&quot; &quot;numeric&quot;
##   .. .. .. ..- attr(*, &quot;names&quot;)= chr [1:2] &quot;Gas&quot; &quot;Temp&quot;
##  - attr(*, &quot;class&quot;)= chr &quot;lm&quot;</code></pre>
<p>At this point, we only want <span class="math inline">\(\hat \beta_{OLS}\)</span> which can be extracted with the <code>coef</code> function.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">coef</span>(lm<span class="fl">.1</span>)</code></pre></div>
<pre><code>## (Intercept)        Temp 
##   6.8538277  -0.3932388</code></pre>
<p>Things to note:</p>
<ul>
<li><p>R automatically adds an <code>(Intercept)</code> term. This means we estimate <span class="math inline">\(y_i=\beta_0 + \beta_1 Gas + \varepsilon\)</span> and not <span class="math inline">\(y_i=\beta_1 Gas + \varepsilon_i\)</span>. This makes sense because we are interested in the variability of the gas consumption about its mean, and not about zero.</p></li>
<li><p>The effect of temperature, i.e., <span class="math inline">\(\hat \beta_1\)</span>, is -0.39. The negative sign means that the higher the temperature, the less gas is consumed. The magnitude of the coefficient means that for a unit increase in the outside temperature, the gas consumption decreases by 0.39 units.</p></li>
</ul>
<p>We can use the <code>predict</code> function to make predictions, but we emphasize that if the purpose of the model is to make predictions, and not interpret coefficients, better skip to The Supervised Learning Chapter <a href="supervised.html#supervised">9</a>.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">plot</span>(<span class="kw">predict</span>(lm<span class="fl">.1</span>)~whiteside[whiteside$Insul==<span class="st">&#39;Before&#39;</span>,]$Gas)
<span class="kw">abline</span>(<span class="dv">0</span>,<span class="dv">1</span>, <span class="dt">lty=</span><span class="dv">2</span>)</code></pre></div>
<p><img src="Rcourse_files/figure-html/unnamed-chunk-107-1.png" width="50%" /></p>
<p>The model seems to fit the data nicely. A common measure of the goodness of fit is the <em>coefficient of determination</em>, more commonly known as the <span class="math inline">\(R^2\)</span>.</p>

<div class="definition">
<span id="def:unnamed-chunk-108" class="definition"><strong>Definition 5.1 </strong></span>The coefficient of determination, denoted <span class="math inline">\(R^2\)</span>, is defined as
<span class="math display">\[\begin{align}
  R^2:= 1-\frac{\sum_i (y_i - \hat y_i)^2}{\sum_i (y_i - \bar y)^2}
\end{align}\]</span>
Where <span class="math inline">\(\hat y_i\)</span> is the model’s prediction, <span class="math inline">\(\hat y_i = x_i \hat \beta\)</span>.
</div>
<p></p>
<p>It can be easily computed</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">R2 &lt;-<span class="st"> </span>function(y, y.hat){
  numerator &lt;-<span class="st"> </span>(y-y.hat)^<span class="dv">2</span> %&gt;%<span class="st"> </span>sum
  denominator &lt;-<span class="st"> </span>(y-<span class="kw">mean</span>(y))^<span class="dv">2</span> %&gt;%<span class="st"> </span>sum
  <span class="dv">1</span>-numerator/denominator
}
<span class="kw">R2</span>(whiteside[whiteside$Insul==<span class="st">&#39;Before&#39;</span>,]$Gas, <span class="kw">predict</span>(lm<span class="fl">.1</span>))</code></pre></div>
<pre><code>## [1] 0.9438081</code></pre>
<p>Obviously, R does provide the means to compute something as basic as <span class="math inline">\(R^2\)</span>, but I will let you find it for yourselves.</p>
</div>
<div id="inference" class="section level2">
<h2><span class="header-section-number">5.3</span> Inference</h2>
<p>To perform inference on <span class="math inline">\(\hat \beta\)</span> in order to test hypotheses and construct confidence intervals, we need to quantify the uncertainly in the reported <span class="math inline">\(\hat \beta\)</span>. This is exactly what Eq.<a href="lm.html#eq:ols-distribution">(5.6)</a> gives us.</p>
<p>Luckily, we don’t need to manipulate multivariate distributions manually, and everything we need is already implemented. The most important function is <code>summary</code> which gives us an overview of the model’s fit. We emphasize that that fitting a model with <code>lm</code> is an assumption free algorithmic step. Inference using <code>summary</code> is <strong>not</strong> assumption free, and requires the set of assumptions leading to Eq.<a href="lm.html#eq:ols-distribution">(5.6)</a>.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">summary</span>(lm<span class="fl">.1</span>)</code></pre></div>
<pre><code>## 
## Call:
## lm(formula = Gas ~ Temp, data = whiteside[whiteside$Insul == 
##     &quot;Before&quot;, ])
## 
## Residuals:
##      Min       1Q   Median       3Q      Max 
## -0.62020 -0.19947  0.06068  0.16770  0.59778 
## 
## Coefficients:
##             Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept)  6.85383    0.11842   57.88   &lt;2e-16 ***
## Temp        -0.39324    0.01959  -20.08   &lt;2e-16 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 0.2813 on 24 degrees of freedom
## Multiple R-squared:  0.9438, Adjusted R-squared:  0.9415 
## F-statistic: 403.1 on 1 and 24 DF,  p-value: &lt; 2.2e-16</code></pre>
<p>Things to note:</p>
<ul>
<li>The estimated <span class="math inline">\(\hat \beta\)</span> is reported in the `Coefficients’ table, which has point estimates, standard errors, t-statistics, and the p-values of a two-sided hypothesis test for each coefficient <span class="math inline">\(H_{0,j}:\beta_j=0, j=1,\dots,p\)</span>.</li>
<li>The <span class="math inline">\(R^2\)</span> is reported at the bottom. The “Adjusted R-squared” is a variation that compensates for the model’s complexity.</li>
<li>The original call to <code>lm</code> is saved in the <code>Call</code> section.</li>
<li>Some summary statistics of the residuals (<span class="math inline">\(y_i-\hat y_i\)</span>) in the <code>Residuals</code> section.</li>
<li>The “residuals standard error”<a href="#fn9" class="footnoteRef" id="fnref9"><sup>9</sup></a> is <span class="math inline">\(\sqrt{(n-p)^{-1} \sum_i (y_i-\hat y_i)^2}\)</span>. The “degrees of freedom” are <span class="math inline">\(n-p\)</span> which can be thought of as the hardness of the problem.</li>
</ul>
<p>As the name suggests, <code>summary</code> is merely a summary. The full <code>summary(lm.1)</code> object is a monstrous object. Its various elements can be queried using <code>str(sumary(lm.1))</code>.</p>
<p>Can we check the assumptions required for inference? Some. Let’s start with the linearity assumption. If we were wrong, and the data is not arranged about a linear line, the residuals will have some shape.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">plot</span>(<span class="kw">residuals</span>(lm<span class="fl">.1</span>)~whiteside[whiteside$Insul==<span class="st">&#39;Before&#39;</span>,]$Temp); <span class="kw">abline</span>(<span class="dv">0</span>,<span class="dv">0</span>, <span class="dt">lty=</span><span class="dv">2</span>)</code></pre></div>
<p><img src="Rcourse_files/figure-html/unnamed-chunk-111-1.png" width="50%" /></p>
<p>I can’t say I see any shape. Let’s fit a <strong>wrong</strong> model, just to see what “shape” means.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">lm<span class="fl">.1.1</span> &lt;-<span class="st"> </span><span class="kw">lm</span>(Gas~<span class="kw">I</span>(Temp^<span class="dv">2</span>), <span class="dt">data=</span>whiteside[whiteside$Insul==<span class="st">&#39;Before&#39;</span>,])
<span class="kw">plot</span>(<span class="kw">residuals</span>(lm<span class="fl">.1.1</span>)~whiteside[whiteside$Insul==<span class="st">&#39;Before&#39;</span>,]$Temp); <span class="kw">abline</span>(<span class="dv">0</span>,<span class="dv">0</span>, <span class="dt">lty=</span><span class="dv">2</span>)</code></pre></div>
<p><img src="Rcourse_files/figure-html/unnamed-chunk-112-1.png" width="50%" /></p>
<p>Things to note:</p>
<ul>
<li>We used <code>I(Temp)^2</code> to specify the model <span class="math inline">\(Gas_i=\beta_0 + \beta_1 Temp^2+ \varepsilon\)</span>.</li>
<li>The residuals have a “belly”. Because they are not a cloud of noise around the linear trend, and we have the wrong model.</li>
</ul>
<p>To the next assumption. We assumed <span class="math inline">\(\varepsilon_i\)</span> are independent of everything else. The residuals, <span class="math inline">\(y_i-\hat y_i\)</span> can be thought of a sample of <span class="math inline">\(\varepsilon_i\)</span>. When diagnosing the linearity assumption, we already saw their distribution does not vary with the <span class="math inline">\(x\)</span>’s, <code>Temp</code> in our case. They may be correlated with themselves; a positive departure from the model, may be followed by a series of positive departures etc. Diagnosing these <em>auto-correlations</em> is a real art, which is not part of our course.</p>
<p>The last assumption we required is normality. As previously stated, if <span class="math inline">\(n \gg p\)</span>, this assumption is not really needed. If <span class="math inline">\(n \sim p\)</span>, i.e., <span class="math inline">\(n\)</span> is in the order of <span class="math inline">\(p\)</span>, we need to verify this assumption. My favorite tool for this task is the <em>qqplot</em>. A qqplot compares the quantiles of the sample with the respective quantiles of an assumed distribution. If quantiles align along a line, the assumed distribution if OK. If quantiles depart from a line, then clearly the assumed distribution does not fit the sample.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">qqnorm</span>(<span class="kw">resid</span>((lm<span class="fl">.1</span>)))</code></pre></div>
<p><img src="Rcourse_files/figure-html/unnamed-chunk-113-1.png" width="50%" /></p>
<p>The <code>qqnorm</code> function plots a qqplot against a normal distribution. Judging from the figure, the normality assumption is quite plausible. Let’s try the same on a non-normal sample, namely a uniformly distributed sample, to see how that would look.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">qqnorm</span>(<span class="kw">runif</span>(<span class="dv">100</span>))</code></pre></div>
<p><img src="Rcourse_files/figure-html/unnamed-chunk-114-1.png" width="50%" /></p>
<div id="testing-a-hypothesis-on-a-single-coefficient" class="section level3">
<h3><span class="header-section-number">5.3.1</span> Testing a Hypothesis on a Single Coefficient</h3>
<p>The first inferential test we consider is a hypothesis test on a single coefficient. In our gas example, we may want to test that the temperature has no effect on the gas consumption. The answer for that is given immediately by <code>summary(lm.1)</code></p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">summary.lm1 &lt;-<span class="st"> </span><span class="kw">summary</span>(lm<span class="fl">.1</span>)
coefs.lm1 &lt;-<span class="st"> </span>summary.lm1$coefficients
coefs.lm1</code></pre></div>
<pre><code>##               Estimate Std. Error   t value     Pr(&gt;|t|)
## (Intercept)  6.8538277 0.11842341  57.87561 2.717533e-27
## Temp        -0.3932388 0.01958601 -20.07754 1.640469e-16</code></pre>
<p>We see that the p-value for <span class="math inline">\(H_{0,1}:\hat \beta_1=0\)</span> against a two sided alternative is effectively 0.</p>
</div>
<div id="constructing-a-confidence-interval-on-a-single-coefficient" class="section level3">
<h3><span class="header-section-number">5.3.2</span> Constructing a Confidence Interval on a Single Coefficient</h3>
<p>Since the <code>summary</code> function gives us the standard errors of <span class="math inline">\(\hat \beta\)</span>, we can immediately compute <span class="math inline">\(\hat \beta_j \pm 2 \sqrt{Var[\hat \beta_j]}\)</span> to get ourselves a (roughly) <span class="math inline">\(95\%\)</span> confidence interval. In our example the interval is</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">coefs.lm1[<span class="dv">2</span>,<span class="dv">1</span>] +<span class="st"> </span><span class="kw">c</span>(-<span class="dv">1</span>,<span class="dv">1</span>) *<span class="st"> </span>coefs.lm1[<span class="dv">2</span>,<span class="dv">2</span>]</code></pre></div>
<pre><code>## [1] -0.4128248 -0.3736528</code></pre>
</div>
<div id="multiple-regression" class="section level3">
<h3><span class="header-section-number">5.3.3</span> Multiple Regression</h3>

<div class="remark">
<span class="remark"><em>Remark. </em></span> <em>Multiple regression</em> is not to be confused with <em>multivariate regression</em> discussed in Chapter <a href="multivariate.html#multivariate">8</a>.
</div>
<p></p>
<p>The data we now use<a href="#fn10" class="footnoteRef" id="fnref10"><sup>10</sup></a> contains a hypothetical sample of <span class="math inline">\(60\)</span> participants who are divided into three stress reduction treatment groups (mental, physical, and medical) and two gender groups (male and female). The stress reduction values are represented on a scale that ranges from 1 to 5. This dataset can be conceptualized as a comparison between three stress treatment programs, one using mental methods, one using physical training, and one using medication across genders. The values represent how effective the treatment programs were at reducing participant’s stress levels, with higher numbers indicating higher effectiveness.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">data &lt;-<span class="st"> </span><span class="kw">read.csv</span>(<span class="st">&#39;dataset_anova_twoWay_comparisons.csv&#39;</span>)
<span class="kw">head</span>(data)</code></pre></div>
<pre><code>##   Treatment   Age StressReduction
## 1    mental young              10
## 2    mental young               9
## 3    mental young               8
## 4    mental   mid               7
## 5    mental   mid               6
## 6    mental   mid               5</code></pre>
<p>How many observations per group?</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">table</span>(data$Treatment, data$Age)</code></pre></div>
<pre><code>##           
##            mid old young
##   medical    3   3     3
##   mental     3   3     3
##   physical   3   3     3</code></pre>
<p>Since we have two factorial predictors, this multiple regression is nothing but a <em>two way ANOVA</em>. Let’s fit the model and inspect it.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">lm<span class="fl">.2</span> &lt;-<span class="st"> </span><span class="kw">lm</span>(StressReduction~.-<span class="dv">1</span>,<span class="dt">data=</span>data)
<span class="kw">summary</span>(lm<span class="fl">.2</span>)</code></pre></div>
<pre><code>## 
## Call:
## lm(formula = StressReduction ~ . - 1, data = data)
## 
## Residuals:
##    Min     1Q Median     3Q    Max 
##     -1     -1      0      1      1 
## 
## Coefficients:
##                   Estimate Std. Error t value Pr(&gt;|t|)    
## Treatmentmedical    4.0000     0.3892  10.276 7.34e-10 ***
## Treatmentmental     6.0000     0.3892  15.414 2.84e-13 ***
## Treatmentphysical   5.0000     0.3892  12.845 1.06e-11 ***
## Ageold             -3.0000     0.4264  -7.036 4.65e-07 ***
## Ageyoung            3.0000     0.4264   7.036 4.65e-07 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 0.9045 on 22 degrees of freedom
## Multiple R-squared:  0.9794, Adjusted R-squared:  0.9747 
## F-statistic:   209 on 5 and 22 DF,  p-value: &lt; 2.2e-16</code></pre>
<p>Things to note:</p>
<ul>
<li><p>The <code>StressReduction~.</code> syntax is read as “Stress reduction as a function of everything else”.</p></li>
<li><p>The <code>StressReduction~.-1</code> means that I do not want an intercept in the model, so that the baseline response is 0.</p></li>
<li><p>All the (main) effects seem to be significant.</p></li>
<li><p>The data has 2 factors, but the coefficients table has 4 predictors. This is because <code>lm</code> noticed that <code>Treatment</code> and <code>Age</code> are factors. Their numerical values are meaningless, and it has thus constructed a dummy variable for each level of each factor. The names of the effect are a concatenation of the factor’s name, and its level. You can inspect these dummy variables with the <code>model.matrix</code> command.</p></li>
</ul>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">head</span>(<span class="kw">model.matrix</span>(lm<span class="fl">.2</span>))</code></pre></div>
<pre><code>##   Treatmentmedical Treatmentmental Treatmentphysical Ageold Ageyoung
## 1                0               1                 0      0        1
## 2                0               1                 0      0        1
## 3                0               1                 0      0        1
## 4                0               1                 0      0        0
## 5                0               1                 0      0        0
## 6                0               1                 0      0        0</code></pre>
<p>If you don’t want the default dummy coding, look at <code>?contrasts</code>.</p>
<p>If you are more familiar with the ANOVA literature, or that you don’t want the effects of each level separately, but rather, the effect of <strong>all</strong> the levels of each factor, use the <code>anova</code> command.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">anova</span>(lm<span class="fl">.2</span>)</code></pre></div>
<pre><code>## Analysis of Variance Table
## 
## Response: StressReduction
##           Df Sum Sq Mean Sq F value Pr(&gt;F)    
## Treatment  3    693 231.000  282.33 &lt;2e-16 ***
## Age        2    162  81.000   99.00  1e-11 ***
## Residuals 22     18   0.818                   
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1</code></pre>
<p>Things to note:</p>
<ul>
<li>The ANOVA table, unlike the <code>summary</code> function, tests if any of the levels of a factor has an effect, and not one level at a time.</li>
<li>The significance of each factor is computed using an F-test.</li>
<li>The degrees of freedom, encoding the nubmer of levels of a factor, is given in the <code>Df</code> column.</li>
<li>The StressReduction seems to vary for different ages and treatments, since both factors are significant.</li>
</ul>
<p>As in any two-way ANOVA, we may want to ask if different age groups respond differently to different treatments. In the statistical parlance, this is called an <em>interaction</em>, or more precisely, an <em>interaction of order 2</em>.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">lm<span class="fl">.3</span> &lt;-<span class="st"> </span><span class="kw">lm</span>(StressReduction~Treatment+Age+Treatment:Age<span class="dv">-1</span>,<span class="dt">data=</span>data)</code></pre></div>
<p>The syntax <code>StressReduction~Treatment+Age+Treatment:Age-1</code> tells R to include main effects of Treatment, Age, and their interactions. Here are other ways to specify the same model.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">lm<span class="fl">.3</span> &lt;-<span class="st"> </span><span class="kw">lm</span>(StressReduction ~<span class="st"> </span>Treatment *<span class="st"> </span>Age -<span class="st"> </span><span class="dv">1</span>,<span class="dt">data=</span>data)
lm<span class="fl">.3</span> &lt;-<span class="st"> </span><span class="kw">lm</span>(StressReduction~(.)^<span class="dv">2</span> -<span class="st"> </span><span class="dv">1</span>,<span class="dt">data=</span>data)</code></pre></div>
<p>The syntax <code>Treatment * Age</code> means “mains effects with second order interactions”. The syntax <code>(.)^2</code> means “everything with second order interactions”</p>
<p>Lets inspect the model</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">summary</span>(lm<span class="fl">.3</span>)</code></pre></div>
<pre><code>## 
## Call:
## lm(formula = StressReduction ~ Treatment + Age + Treatment:Age - 
##     1, data = data)
## 
## Residuals:
##    Min     1Q Median     3Q    Max 
##     -1     -1      0      1      1 
## 
## Coefficients:
##                              Estimate Std. Error t value Pr(&gt;|t|)    
## Treatmentmedical            4.000e+00  5.774e-01   6.928 1.78e-06 ***
## Treatmentmental             6.000e+00  5.774e-01  10.392 4.92e-09 ***
## Treatmentphysical           5.000e+00  5.774e-01   8.660 7.78e-08 ***
## Ageold                     -3.000e+00  8.165e-01  -3.674  0.00174 ** 
## Ageyoung                    3.000e+00  8.165e-01   3.674  0.00174 ** 
## Treatmentmental:Ageold      4.246e-16  1.155e+00   0.000  1.00000    
## Treatmentphysical:Ageold    1.034e-15  1.155e+00   0.000  1.00000    
## Treatmentmental:Ageyoung   -3.126e-16  1.155e+00   0.000  1.00000    
## Treatmentphysical:Ageyoung  5.128e-16  1.155e+00   0.000  1.00000    
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 1 on 18 degrees of freedom
## Multiple R-squared:  0.9794, Adjusted R-squared:  0.9691 
## F-statistic:    95 on 9 and 18 DF,  p-value: 2.556e-13</code></pre>
<p>Things to note:</p>
<ul>
<li>There are still <span class="math inline">\(5\)</span> main effects, but also <span class="math inline">\(4\)</span> interactions. This is because when allowing a different average response for every <span class="math inline">\(Treatment*Age\)</span> combination, we are effectively estimating <span class="math inline">\(3*3=9\)</span> cell means, even if they are not parametrized as cell means, but rather as main effect and interactions.</li>
<li>The interactions do not seem to be significant.</li>
</ul>
<p>Asking if all the interactions are significant, is asking if the different age groups have the same response to different treatments. Can we answer that based on the various interactions? We might, but it is possible that no single interaction is significant, while the combination is. To test for all the interactions together, we can simply check if the model without interactions is (significantly) better than a model with interactions. I.e., compare <code>lm.2</code> to <code>lm.3</code>. This is done with the <code>anova</code> command.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">anova</span>(lm<span class="fl">.2</span>,lm<span class="fl">.3</span>, <span class="dt">test=</span><span class="st">&#39;F&#39;</span>)</code></pre></div>
<pre><code>## Analysis of Variance Table
## 
## Model 1: StressReduction ~ (Treatment + Age) - 1
## Model 2: StressReduction ~ Treatment + Age + Treatment:Age - 1
##   Res.Df RSS Df Sum of Sq  F Pr(&gt;F)
## 1     22  18                       
## 2     18  18  4         0  0      1</code></pre>
<p>We see that <code>lm.3</code> is <strong>not</strong> better than <code>lm.2</code>, so that we can conclude that there are no interactions: different ages have the same response to different treatments.</p>
</div>
<div id="testing-a-hypothesis-on-a-single-contrast" class="section level3">
<h3><span class="header-section-number">5.3.4</span> Testing a Hypothesis on a Single Contrast</h3>
<p>Returning to <code>lm.2</code>.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">coef</span>(<span class="kw">summary</span>(lm<span class="fl">.2</span>))</code></pre></div>
<pre><code>##                   Estimate Std. Error   t value     Pr(&gt;|t|)
## Treatmentmedical         4  0.3892495 10.276186 7.336391e-10
## Treatmentmental          6  0.3892495 15.414279 2.835706e-13
## Treatmentphysical        5  0.3892495 12.845233 1.064101e-11
## Ageold                  -3  0.4264014 -7.035624 4.647299e-07
## Ageyoung                 3  0.4264014  7.035624 4.647299e-07</code></pre>
<p>We see that the effect of the various treatments is rather similar. It is possible that all treatments actually have the same effect. Comparing the levels of a factor is called a <em>contrast</em>. Let’s test if the medical treatment, has in fact, the same effect as the physical treatment.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">library</span>(multcomp)
my.contrast &lt;-<span class="st"> </span><span class="kw">matrix</span>(<span class="kw">c</span>(-<span class="dv">1</span>,<span class="dv">0</span>,<span class="dv">1</span>,<span class="dv">0</span>,<span class="dv">0</span>), <span class="dt">nrow =</span>  <span class="dv">1</span>)
lm<span class="fl">.4</span> &lt;-<span class="st"> </span><span class="kw">glht</span>(lm<span class="fl">.2</span>, <span class="dt">linfct=</span>my.contrast)
<span class="kw">summary</span>(lm<span class="fl">.4</span>)</code></pre></div>
<pre><code>## 
##   Simultaneous Tests for General Linear Hypotheses
## 
## Fit: lm(formula = StressReduction ~ . - 1, data = data)
## 
## Linear Hypotheses:
##        Estimate Std. Error t value Pr(&gt;|t|)  
## 1 == 0   1.0000     0.4264   2.345   0.0284 *
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## (Adjusted p values reported -- single-step method)</code></pre>
<p>Things to note:</p>
<ul>
<li>A contrast is a linear function of the coefficients. In our example <span class="math inline">\(H_0:\beta_1-\beta_3=0\)</span>, which justifies the construction of `my.contrast’.</li>
<li>We used the <code>glht</code> function (generalized linear hypothesis test) from the package <strong>multcompt</strong>.</li>
<li>The contrast is significant, i.e., the effect of a medical treatment, is different than that of a physical treatment.</li>
</ul>
</div>
</div>
<div id="bibliographic-notes-3" class="section level2">
<h2><span class="header-section-number">5.4</span> Bibliographic Notes</h2>
<p>Like any other topic in this book, you can consult <span class="citation">Venables and Ripley (<a href="#ref-venables2013modern">2013</a>)</span> for more on linear models. For the theory of linear models, I like <span class="citation">Greene (<a href="#ref-greene2003econometric">2003</a>)</span>.</p>

</div>
</div>
<h3> Bibliography</h3>
<div id="refs" class="references">
<div id="ref-friedman2001elements">
<p>Friedman, Jerome, Trevor Hastie, and Robert Tibshirani. 2001. <em>The Elements of Statistical Learning</em>. Vol. 1. Springer series in statistics Springer, Berlin.</p>
</div>
<div id="ref-venables2013modern">
<p>Venables, William N, and Brian D Ripley. 2013. <em>Modern Applied Statistics with S-Plus</em>. Springer Science &amp; Business Media.</p>
</div>
<div id="ref-greene2003econometric">
<p>Greene, William H. 2003. <em>Econometric Analysis</em>. Pearson Education India.</p>
</div>
</div>
<div class="footnotes">
<hr />
<ol start="5">
<li id="fn5"><p>The “response” is also know as the “dependent” variable, of the “labels” in the machine learning literature.<a href="lm.html#fnref5">↩</a></p></li>
<li id="fn6"><p>The “factors” are also known as the “independent variable”, the “design”, the “features” and the “attributes”.<a href="lm.html#fnref6">↩</a></p></li>
<li id="fn7"><p>The “error term” is also known as the “noise”, or the “common causes of variability”.<a href="lm.html#fnref7">↩</a></p></li>
<li id="fn8"><p>By “computed” we mean what statisticians call “fitted”, or “estimated”, and computer scientists call “learned”.<a href="lm.html#fnref8">↩</a></p></li>
<li id="fn9"><p>Sometimes known as the Root Mean Squared Error (RMSE).<a href="lm.html#fnref9">↩</a></p></li>
<li id="fn10"><p>The example is taken from <a href="http://rtutorialseries.blogspot.co.il/2011/02/r-tutorial-series-two-way-anova-with.html" class="uri">http://rtutorialseries.blogspot.co.il/2011/02/r-tutorial-series-two-way-anova-with.html</a><a href="lm.html#fnref10">↩</a></p></li>
</ol>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="eda.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="glm.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/lunr.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script>
require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"google": false,
"weibo": false,
"instapper": false,
"vk": false,
"all": ["facebook", "google", "twitter", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": "https://github.com/rstudio/bookdown-demo/edit/master/04-lm.Rmd",
"text": "Edit"
},
"download": null,
"toc": {
"collapse": "subsection"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    script.src  = "https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML";
    if (location.protocol !== "file:" && /^https?:/.test(script.src))
      script.src  = script.src.replace(/^https?:/, '');
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
