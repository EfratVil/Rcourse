# Linear Mixed Models {#lme}

```{example, label='fixed-effects', name="Fixed and Random Machine Effect"}
Consider the problem of testing for a change in the distribution of manufactured bottle caps.
Bottle caps are produced by several machines.
We could standardize over machines by removing each machine's average. 
This implies the within-machine variability is the only source of variability we care about. 
Alternatively, we could ignore the machine of origin. 
This second practice implies there are two sources of variability we care about: the within-machine variability, and the between-machine variability.
The former practice is known as a _fixed effects_  model.
The latter as a _random effects_ model.
```


```{example, label='random-effects', name="Fixed and Random Subject Effect"}
Consider a crossover^[If you are unfamiliar with design of experiments, have a look at Chapter 6 of my Quality Engineering [class notes](https://github.com/johnros/qualityEngineering/blob/master/Class_notes/notes.pdf).] experimenal design where each subject is given 2 types of diets, and his health condition is recorded.
We could standardize over subjects by removing the subject-wise average, before comparing diets.
This is what a paired t-test does, and implies the within-subject variability is the only source of variability we care about.
Alternatively, we could ignore the subject of origin. 
This second practice implies there are two sources of variability we care about: the within-subject variability and the betwee-subject variability.
```

The unifying theme of the above two examples, is that the variability we want to infer against has several sources. 
Which are the sources of variability that need to concern us? 
It depends on your purpose...

Mixed models are so fundamental, that they have earned many names:

- __Mixed Effects__: 
Because we may have both _fixed effects_ we want to estimate and remove, and _random effects_ which contribute to the variability to infer against.

- __Variance Components__: 
Because as the examples show, variance has more than a single source (like in the Linear Models of Chapter \@ref(lm)).

- __Hirarchial Models__: 
Because as Example \@ref(exm:random-effects) demonstrates, we can think of the sampling as hierarchical-- first sample a subject, and then sample its response. 

- __Repeated Measures__: 
Because we make several measurements from each unit, like in Example \@ref(exm:random-effects).

- __Longitudinal Data__: 
Because we follow units over time, like in Example \@ref(exm:random-effects).

- __Panel Data__:
Is the term typically used in econometric for such longitudinal data. 

- __MANOVA__:
Many of the problems that may be solved with a multivariate analysis of variance (MANOVA), may be solved with a mixed model for reasons we detail in \@ref(multivariate).


We now emphasize: 

1. Mixed effect models are a way to infer against the right level of variability.
Using a naive linear model (which assumes a single source of variability) instead of a mixed effects model, probably means your inference is overly anti-conservative. Put differently, the uncertainty in your estimates is higher than the linear model from Chapter \@ref(lm) may suggest.
1. A mixed effect models, as we will later see, is typically specified via its fixed and random effects. 
It is possible, however, to specify a mixed effects model by putting all the fixed effects into a linear model, and putting all the random effects into the covariance matrix of $\varepsilon$. This is known as _multivariate regression_, or _multivariate analysis of variance_ (MANOVA).
For more on this view, see Chapter 8 in (the excellent) @weiss2005modeling.
1. Like in previous chapters, by "model" we refer to the assumed generative distribution, i.e., the sampling distribution. 
1. If you are using the model merely for predictions, and not for inference on the fixed effects or variance components, then stating the generative distribution may be be useful, but not necessarily. 
See the Supervised Learning Chapter \@ref(supervised) for more on prediction problems.
Also recall that machine learning from non-independent observations (such as mixed models) is a delicate matter that is rarely treated in the literature. 


## Problem Setup

\begin{align}
  y|x,u = x'\beta + z'u + \varepsilon
  (\#eq:mixed-model)  
\end{align}
where $x$ are the factors with fixed effects, $\beta$, which we may want to study.
The factors $z$, with effects $u$, are the random effects which contribute to variability. 
In our diet exaple (\@ref(exm:random-effects))

The reader may notice that we state $y|x,u$ merely as a convenient way to do inference on $y|x$, instead of directly specifying $Var[y|x]$.

Given a sample of $n$ observations $(y_i,x_i,z_i)$ from model \@ref(eq:mixed-model), we will want to estimate $(\beta,u)$.
Under some assumption on the distribution of $\varepsilon$ and $z$, we can use _maximum likelihood_ (ML). 
In the context of mixed-models, however, ML is typically replaced with _restricted maximum likelihood_ (ReML), because it returns unbiased estimates of $Var[y|x]$ and ML does not.

AH todo: Something went wrong:
### Relation to MANOVA (*) {#manova}
Multivariate analysis of variance (MANOVA) deals with the estimation of effect on vector valued outcomes. 
Put differently: in ANOVA the response, $y$, is univariate In MANOVA, the outcome is multivariate.
MANOVA is useful when there are correlations among the entries of $y$.
Otherwise- one may simply solve many ANOVA problems, instead of a single MANOVA.

Now assume that the outcome of a MANOVA is measurements of an individual at several time periods.
The measurements are clearly correlated, so that MANOVA may be useful. 
But one may also treat time as a random effect, with a univariate response. 
We thus see that this seemingly MANOVA problem can be solved with the mixed models framework.

What MANOVA problems cannot be solved with mixed models?
There may be cases where the covariance of the multivariate outcome, $y$, is very complicated.
If the covariance in $y$ may not be stated using a combination of random and fixed effects, then the covariance has to be stated explicitly in the MANOVA framework.
It is also possible to consider mixed-models with multivariate outcomes, i.e., a _mixed MANOVA_, or _hirarchial MANOVA_.
The R functions we present herein permit this.




## Mixed Models with R

We will fit mixed models with the `lmer` function from the __lme4__ package, written by the mixed-models Guru [Douglas Bates](http://www.stat.wisc.edu/~bates/).
We start with a small simulation demonstrating the importance of acknowledging your sources of variability, by fitting a linear model when a mixed model is appropriate. 
We start by creating some synthetic data. 

```{r}
n.groups <- 10
n.repeats <- 2
groups <- gl(n = n.groups, k = n.repeats) # create the group factor
n <- length(groups)
z0 <- rnorm(10,0,10) # generate group effects
z <- z0[as.numeric(groups)] # assign effect to group
epsilon <- rnorm(n,0,1) # generate measurement error
beta0 <- 2 # set global mean
y <- beta0 + z  + epsilon # generate synthetic sample
```

We can now fit the linear and mixed models.
```{r, lme vs lm}
lm.5 <- lm(y~z)  # fit a linear model
library(lme4)
lme.5 <- lmer(y~1|groups) # fit a mixed-model
```


The summary of the linear model

```{r, label='lm5'}
summary.lm.5 <- summary(lm.5)
summary.lm.5
```

The summary of the mixed-model

```{r, label='lme5'}
summary.lme.5 <- summary(lme.5)
summary.lme.5
```
Look at the standard error of the global mean, i.e., the intercept:
for `lm` it is `r summary.lm.5$coefficients[1,2]`, and for `lme` it is `r summary.lme.5$coefficients[1,2]`.
Why this difference? 
Because `lm` discounts the group effect^[A.k.a. the _cluster effect_ in the epidemiological literature. ], while it should treat it as another source of variability.
Clearly, inference using `lm` underestimates our uncertainty.

### A Single Random Effect

We will use the `Dyestuff` data from the __lme4__ package, which encodes the yield, in grams, of a coloring solution (dyestuff), produced in 6 batches using 5 different preparations.

```{r}
data(Dyestuff, package='lme4')
attach(Dyestuff)
head(Dyestuff)
```

And visually

```{r}
plot(Yield~Batch)
```

If we want to do inference on the mean yield, we need to account for the two sources of variability: the batch effect, and the measurement error. 
We thus fit a mixed model, with an intercept and random batch effect, which means this is it not a bona-fide mixed-model, but rather, a simple random-effect model.

```{r random intercept}
lme.1<- lmer( Yield ~ 1  | Batch  , Dyestuff )
summary(lme.1)
```

Things to note:

- As usual, `summary` is content aware and has a different behavior for `lme` class objects.
- The syntax `Yield ~ 1  | Batch` tells R to fit a model with a global intercept (`1`) and a random Batch effect (`|Batch`). More on that later. 
- The output distinguishes between random effects, a source of variability, and fixed effect, which's coefficients we want to study. The mean of the random effect is not reported because it is assumigly 0 for all random effects.
- Were we not interested in the variance components, and only in the coefficients or predictions, an (almost) equivalent `lm` formulation is `lm(Yield ~ Batch)`.

Some utility functions let us query the `lme` object. 
The function `coef` will work, but will return a cumbersome output. Better use `fixef` to extract the fixed effects, and `ranef` to extract the random effects.
The model matrix (of the fixed effects alone), can be extracted with `model.matrix`, and predictions made with `predict`.
Note, however, that predictions with mixed-effect models are (i) a delicate matter, and (ii) better treated as prediction problems as in the Supervised Learning Chapter \@ref(supervised).

```{r}
detach(Dyestuff)
```


### Multiple Random Effects

Let's make things more interesting by allowing more than one random effect. 
One-way ANOVA can be thought of as the fixed-effects counterpart of the single random effect.
Our next example, involving two random effects, can be though of as the Two-way ANOVA counterpart. 

In the `Penicillin` data, we measured the diameter of spread of an organism, along the plate used (a to x), and penicillin type (A to F). 

```{r}
head(Penicillin)
```

One sample per combination:

```{r}
attach(Penicillin)
table(sample, plate) # how many observations per plate & type?
```

And visually:

```{r, echo=FALSE}
lattice::dotplot(reorder(plate, diameter) ~ diameter,data=Penicillin,
              groups = sample,
              ylab = "Plate", xlab = "Diameter of growth inhibition zone (mm)",
              type = c("p", "a"), auto.key = list(columns = 6, lines = TRUE))
```

Let's fit a mixed-effects model with a random plate effect, and a random sample effect:

```{r}
lme.2 <- lmer ( diameter ~  1+ (1| plate ) + (1| sample ) , Penicillin )
fixef(lme.2) # Fixed effects
ranef(lme.2) # Random effects
```

Things to note:

- The syntax `1+ (1| plate ) + (1| sample )` fits a global intercept (mean), a random plate effect, and a random sample effect.
- Were we not interested in the variance components, an (almost) equivalent `lm` formulation is `lm(diameter ~ plate + sample)`.
- The output of `ranef` is somewhat controvertial. Think about it: Why would we want to plot the estimates of a random variable? 



Since we have two random effects, we may compute the variability of the global mean (the only fixed effect) as we did before. 
Perhaps more interestingly, we can compute the variability in the response, for a particular plate or sample type.

```{r}
random.effect.lme2 <- ranef(lme.2, condVar = TRUE) 
qrr2 <- lattice::dotplot(random.effect.lme2, strip = FALSE)
```

Variability in response for each plate, over various sample types:

```{r}
print(qrr2[[1]]) 
```

Variability in response for each sample type, over the various plates:

```{r}
print(qrr2[[2]])  
```

Things to note:

- The `condVar` argument of the `ranef` function tells R to compute the variability in response conditional on each random effect at a time. 
- The `dotplot` function, from the __lattice__ package, is only there for the fancy plotting.




### A Full Mixed-Model

In the `sleepstudy` data, we recorded the reaction times to a series of tests (`Reaction`), after various subject (`Subject`) underwent various amounts of sleep deprivation (`Day`).

```{r, echo=FALSE}
data(sleepstudy)
lattice::xyplot(Reaction ~ Days | Subject, sleepstudy, aspect = "xy",
             layout = c(9,2), type = c("g", "p", "r"),
             index.cond = function(x,y) coef(lm(y ~ x))[1],
             xlab = "Days of sleep deprivation",
             ylab = "Average reaction time (ms)")
```

We now want to estimate the (fixed) effect of the days of sleep deprivation on response time, while allowing each subject to have his/hers own effect.
Put differently, we want to estimate a _random slope_ for the effect of `day`.
The fixed `Days` effect can be thought of as the average slope over subjects.

```{r random slope}
lme.3 <- lmer ( Reaction ~ Days + ( Days | Subject ) , data= sleepstudy )
```

Things to note:

- `~Days` specifies the fixed effect. 
- We used the `Days|Subect` syntax to tell R we want to fit the model `~Days` within each subject.
- Were we fitting the model for purposes of prediction only, an (almost) equivalent `lm` formulation is `lm(Reaction~Days*Subject)`.


The fixed day effect is:

```{r}
fixef(lme.3)
```

The variability in the average response (intercept) and day effect is

```{r}
ranef(lme.3)
```

Did we really need the whole `lme` machinery to fit a within-subject linear regression and then average over subjects?
The answer is yes.
The assumptions on the distribution of random effect, namely, that they are normally distributed, allows us to pool information from one subject to another. In the words of John Tukey: "we borrow strength over subjects".
Is this a good thing? If the normality assumption is true, it certainly is.
If, on the other hand, you have a lot of samples per subject, and you don't need to "borrow strength" from one subject to another, you can simply fit within-subject linear models without the mixed-models machinery.

To demonstrate the "strength borrowing", here is a comparison of the subject-wise intercepts of the mixed-model, versus a subject-wise linear model. They are not the same.

```{r, echo=FALSE}
library(lattice)
df <- coef(lmList(Reaction ~ Days | Subject, sleepstudy))
fclow <- subset(df, `(Intercept)` < 251)
fchigh <- subset(df, `(Intercept)` > 251)
cc1 <- as.data.frame(coef(lme.3)$Subject)
names(cc1) <- c("A", "B")
df <- cbind(df, cc1)
ff <- fixef(lme.3)
with(df,
     print(xyplot(`(Intercept)` ~ Days, aspect = 1,
                  x1 = B, y1 = A,
                  panel = function(x, y, x1, y1, subscripts, ...) {
                    panel.grid(h = -1, v = -1)
                    x1 <- x1[subscripts]
                    y1 <- y1[subscripts]
                    larrows(x, y, x1, y1, type = "closed", length = 0.1,
                            angle = 15, ...)
                    lpoints(x, y,
                            pch = trellis.par.get("superpose.symbol")$pch[2],
                            col = trellis.par.get("superpose.symbol")$col[2])
                    lpoints(x1, y1,
                            pch = trellis.par.get("superpose.symbol")$pch[1],
                            col = trellis.par.get("superpose.symbol")$col[1])
                    lpoints(ff[2], ff[1], 
                            pch = trellis.par.get("superpose.symbol")$pch[3],
                            col = trellis.par.get("superpose.symbol")$col[3])
                    ltext(fclow[,2], fclow[,1], row.names(fclow),
                          adj = c(0.5, 1.7))
                    ltext(fchigh[,2], fchigh[,1], row.names(fchigh),
                          adj = c(0.5, -0.6))
                  },
                  key = list(space = "top", columns = 3,
                             text = list(c("Mixed model", "Within-group", "Population")),
                             points = list(col = trellis.par.get("superpose.symbol")$col[1:3],
                                           pch = trellis.par.get("superpose.symbol")$pch[1:3]))
     )))

```

Here is a comparison of the random-day effect from `lme` versus a subject-wise linear model. They are not the same.

```{r, echo=FALSE}
print(xyplot(Reaction ~ Days | Subject, sleepstudy, aspect = "xy",
             layout = c(9,2), type = c("g", "p", "r"),
             coef.list = df[,3:4],
             panel = function(..., coef.list) {
               panel.xyplot(...)
               panel.abline(as.numeric(coef.list[packet.number(),]),
                            col.line = trellis.par.get("superpose.line")$col[2],
                            lty = trellis.par.get("superpose.line")$lty[2]
               )
               panel.abline(fixef(lme.3),
                            col.line = trellis.par.get("superpose.line")$col[4],
                            lty = trellis.par.get("superpose.line")$lty[4]
               )
             },
             index.cond = function(x,y) coef(lm(y ~ x))[1],
             xlab = "Days of sleep deprivation",
             ylab = "Average reaction time (ms)",
             key = list(space = "top", columns = 3,
                        text = list(c("Within-subject", "Mixed model", "Population")),
                        lines = list(col = trellis.par.get("superpose.line")$col[c(2:1,4)],
                                     lty = trellis.par.get("superpose.line")$lty[c(2:1,4)]))))
```

```{r}
detach(Penicillin)
```


## The Variance-Components View
TODO


## Bibliographic Notes
Most of the examples in this chapter are from the documentation of the __lme4__ package [@lme4]. 
For a more theoretical view see @weiss2005modeling or @searle2009variance.
As usual, a hands on view can be found in @venables2013modern.

## Practice Yourself

1. Return to the `Penicillin` data set. Instead of fitting an LME model, fit an LM model with `lm`. I.e., treat all random effects as fixed. 
    a. Compare the effect estimates. 
    a. Compare the standard errors. 
    a. Compare the predictions of the two models. 
1. [Very Advanced!] Return to the `Penicillin` data and use the `gls` function to fit a generalized linear model, equivalent to the LME model in our text. 
1. Read about the “oats” dataset using `? MASS::oats `.Inspect the dependency of the yield (Y) in the Varieties (V) and the Nitrogen treatment (N).
    1. Fit a linear model, does the effect of the treatment significant? The interaction between the Varieties and Nitrogen is significant?
    1. An expert told you that could be a variance between the different blocks (B) which can bias the analysis. fit a LMM for the data.
    1. Do you think the blocks should be taken into account as “random effect” or “fixed effect”?


