# Memory Efficiency {#memory}

As we have seen in the Sparsity Chapter \@ref(sparse), an efficient representation of your data in RAM will reduce computing time, and will allow you to fit models that would otherwise require tremendous amounts of RAM.
It is possible, however, to avoid altogether the need to fit your data in RAM.
The fundamental idea is that your data can be stored on the HD. 
Since the HD is typically much larger than your RAM, you will be able to compute with much larger data sets. 
The downside is that HDs are much slower than RAM.
This was painfully true when HDs were rotating magnetic plates. 
This is still true, but less painful, now that high-end HDs are not rotating magnetic plates, but rather SSDs.

We will now meet several facilities that will allow you to avoid loading your data to RAM, and still be able to fit models with it.
The fundamental idea is to use efficient file structures, that will save your data in a way that predicts the way the model-fitting process will call it, so that fetching it from HD is efficient.
This is not a unique capability of R. Indeed, SAS, SPSS, Pyton's sci-kit learn, and other software have this same capability.
Moreover, there are many facilities in R that provide this same capability. For instance, the commercial version of R, _Microsoft R_, previously known as _Revolutions R_, provides this capability with the __RevoScaleR__ family of packages. 


